import os
import sys
from pyspark.sql import SparkSession
from pyspark.sql.functions import col

# Configuraci√≥n: Evitamos que cree archivos temporales basura (__pycache__)
sys.dont_write_bytecode = True

def iniciar_sesion_spark():
    """Inicia una sesi√≥n de Spark solo para lectura."""
    return SparkSession.builder \
        .appName("Auditor_Data_Lake") \
        .master("local[*]") \
        .getOrCreate()

def auditar_calidad_datos():
    spark = iniciar_sesion_spark()
    print("\n" + "="*50)
    print("üïµÔ∏è‚Äç‚ôÇÔ∏è  INICIANDO AUDITOR√çA DEL DATA LAKE")
    print("="*50)

    # RUTA A INSPECCIONAR (La Capa Silver Limpia)
    # Nota: Usamos ruta relativa asumiendo que el script corre desde la ra√≠z
    ruta_silver = "output/data_lake_silver_clean"

    # 1. VERIFICACI√ìN DE EXISTENCIA
    if not os.path.exists(ruta_silver):
        print(f"‚ùå ERROR CR√çTICO: No se encuentra la carpeta: {ruta_silver}")
        print("   ¬øEjecutaste el pipeline de limpieza antes?")
        return

    try:
        df = spark.read.parquet(ruta_silver)
        print(f"‚úÖ CONEXI√ìN EXITOSA: Se pudo leer el formato Parquet.")
    except Exception as e:
        print(f"‚ùå ERROR DE FORMATO: Los archivos est√°n corruptos. {e}")
        return

    # 2. AUDITOR√çA DE VOLUMEN
    total_registros = df.count()
    print(f"üìä VOLUMEN: Se encontraron {total_registros} transacciones procesadas.")

    if total_registros == 0:
        print("‚ö†Ô∏è  ALERTA: El Data Lake est√° vac√≠o.")
    
    # 3. AUDITOR√çA DE CALIDAD (Busca si escap√≥ basura)
    # Buscamos nulos en 'monto' o 'cliente_id'
    errores = df.filter(col("monto").isNull() | col("cliente_id").isNull()).count()

    if errores == 0:
        print("‚úÖ CALIDAD APROBADA: 0 registros nulos encontrados.")
        print("   El filtro de limpieza funcion√≥ correctamente.")
    else:
        print(f"‚ùå FALLO DE CALIDAD: Se encontraron {errores} registros sucios.")

    # 4. MUESTRA 
    print("\n--- üîç EVIDENCIA (Muestra Aleatoria) ---")
    df.select("fecha", "tipo", "monto", "sucursal").show(5, truncate=False)

    print("="*50)
    print("üèÅ FIN DE LA AUDITOR√çA")
    print("="*50)
    spark.stop()

if __name__ == "__main__":
    auditar_calidad_datos()